{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning System for Equipment Failure Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. System Overview\n",
    "\n",
    "This machine learning system is designed to showcase an end-to-end implementation covering the entire lifecycle of a machine learning model. It integrates various MLOps tools and technologies discussed during the DASCI 270 sessions, that includes facilitating data ingestion, preprocessing, training, validation, deployment, and monitoring of the model. The system is also structured to handle drift detection to ensure the model remains effective and accurate over time. This document will guide you through interacting with the deployed **Equipment Failure Prediction** system, including making predictions, retrieving model information, and checking data drift, as well as provide detailed documentation of each component and their functionalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### System Architecture\n",
    "\n",
    "! insert diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Components\n",
    "\n",
    "1. **Machine Learning Model (XGBoost for Classification)** - \n",
    "\n",
    "2. **Data Pipeline (Dagster)** - Orchestrates the workflow for data ingestion, preprocessing, and preparation. Dagster manages the sequence of these operations to ensure data flows correctly from one process to another, maintaining a clear and manageable execution order.\n",
    "\n",
    "3. **Experiment Tracking (MLflow)** - Provides a framework to track experiments, including model training runs, parameters, metrics, and artifacts, enabling easier debugging and optimization. It stores models, performance metrics, and custom objects like drift reports, making them easy to access and compare across different runs.\n",
    "\n",
    "4. **Model Serving (FastAPI)** - Deploys the trained model through a REST API using FastAPI, facilitating easy access to the modelâ€™s predictive capabilities. The API handles requests for predictions and provides model metadata, ensuring input validation and structured outputs.\n",
    "\n",
    "5. **Containerization (Docker)** - Containerizes the services making up the system to ensure consistency and reproducibility across environments. Each isolated environment (\"container\") contains all necessary dependencies for each service, which can be easily deployed on any system supporting Docker.\n",
    "\n",
    "6. **Drift Detection (Evidently AI)** - Integrates Evidently AI to monitor the model for any signs of data or concept drift. This component is crucial for maintaining the model's accuracy, providing insights into how the data characteristics and relationships are changing over time.\n",
    "\n",
    "7. **Data Validation (Pydantic)** - Ensures that the data received by the API matches the expected format and type. This prevents errors during model prediction and ensures reliable model performance.\n",
    "\n",
    "8. **Testing (Pytest and Github Actions)** - Uses Pytest to develop and run comprehensive tests that validate the correctness of the data processing and feature engineering components. GitHub Actions automates these tests, ensuring that all code integrations meet quality standards and function as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "\n",
    "This project utilized the AI4I 2020 Predictive Maintenance dataset, a synthetic dataset sourced from UCI Machine Learning Repository: https://archive.ics.uci.edu/dataset/601/ai4i+2020+predictive+maintenance+dataset. It contains 10,000 data points with the following columns/variables:\n",
    "\n",
    "| Variables          | Type        | Description                                                                                         |\n",
    "|--------------------|-------------|-----------------------------------------------------------------------------------------------------|\n",
    "| UID                | Integer     | Unique identifier ranging from 1 to 10000                                                           |\n",
    "| Product ID         | Categorical | Consists of a letter (L, M, H) for low, medium, and high product quality variants with a serial number |\n",
    "| Type               | Categorical | Not specified                                                                                       |\n",
    "| Air temperature    | Continuous  | Generated using a random walk process, normalized around 300 K with a standard deviation of 2 K      |\n",
    "| Process temperature| Continuous  | Generated using a random walk process, normalized to a standard deviation of 1 K, plus air temperature + 10 K |\n",
    "| Rotational speed   | Integer     | Calculated based on a power of 2860 W with normally distributed noise                               |\n",
    "| Torque             | Continuous  | Normally distributed around 40 Nm with a standard deviation of 10 Nm, no negative values             |\n",
    "| Tool wear          | Integer     | Tool wear added by quality variants H/M/L are 5/3/2 minutes respectively                             |\n",
    "| Machine failure    | Integer     | Indicates if the machine has failed (1) or not (0) in this particular datapoint                      |\n",
    "| TWF                | Integer     | Target feature indicating if a specific type of failure occurred or not (1/0)                        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Setup Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section provides detailed instructions on how to set up and run the system using Docker Compose. The instructions assume you have Docker and Docker Compose installed on your machine. If not, please install them from the [Docker official website](https://www.docker.com/) before proceeding.\n",
    "\n",
    "**Step 1: Clone the Repository** <br>\n",
    "First, clone the project repository from GitHub to get the necessary code and configuration files. Use the following command:\n",
    "\n",
    "```python\n",
    "git clone https://github.com/raymundojavajr/ml-fp.git\n",
    "cd ml-fp\n",
    "```\n",
    "\n",
    "This command clones the repository into a directory named ml-fp on your local machine and changes into that directory.\n",
    "\n",
    "**Step 2: Configure Environment Variables** <br>\n",
    "Create a .venv file in the root directory of the project to store environment variables. This can be conveniently done using uv:\n",
    "\n",
    "```python\n",
    "uv sync\n",
    "```\n",
    "\n",
    "It can also be done using pip:\n",
    "\n",
    "```python\n",
    "python -m .venv venv\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "**List of Libraries used in the pipeline:**\n",
    "\n",
    "\n",
    "\n",
    "**Step 3: Build the Docker Containers**\n",
    "Use Docker Compose to build the services defined in the docker-compose.yml file. This includes your Dagster orchestration, MLflow tracking server, and FastAPI application. Run the following command:\n",
    "\n",
    "```python\n",
    "docker-compose build\n",
    "```\n",
    "\n",
    "This command builds the Docker images for each service according to the specifications in the Dockerfile and docker-compose.yml files. It installs all necessary dependencies in these images, ensuring each service has what it needs to run.\n",
    "\n",
    "**Step 4: Run the Services**\n",
    "Once the images are built, you can start the services with the following command:\n",
    "\n",
    "```python\n",
    "docker-compose up\n",
    "```\n",
    "\n",
    "This command starts all services defined in docker-compose.yml. It creates and starts Docker containers for each service. The services will be networked together as defined, allowing them to communicate with each other.\n",
    "\n",
    "**Step 5: Access the Services**\n",
    "* FastAPI Application: Access the FastAPI application at http://localhost:8000. You will find the automatically generated API documentation there, which allows you to interact with the API directly through your web browser.\n",
    "* MLflow Tracking Server: Access the MLflow tracking server at http://localhost:5000. Here you can view and compare different model runs and their metrics.\n",
    "* Dagster Dagit UI: Access the Dagster orchestration UI at http://localhost:3000. This interface allows you to monitor and control the data pipelines.\n",
    "\n",
    "**Step 6: Shut Down the Services**\n",
    "To stop and remove all running containers, use the following command:\n",
    "\n",
    "```python\n",
    "docker-compose down\n",
    "```\n",
    "This command stops all containers and removes the containers, networks, and volumes created by docker-compose up. It cleans up everything except the built images, allowing for a quick restart of the services if needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Happy Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Request\n",
    "\n",
    "In this section, we demonstrate how to use the FastAPI model server for predictions. We'll send a set of equipment parameters and status data to receive predictions on potential machine failures.\n",
    "\n",
    "- **Input Data:** This includes a series of variables such as equipment type, air and process temperatures, rotational speed, torque, tool wear, and previous instances of machine failure.\n",
    "- **API Endpoint:** This is the URL where the FastAPI server accepts prediction requests.\n",
    "- **Response Handling:** Upon receiving the prediction request, the server provides a forecast indicating whether a machine is likely to fail. This prediction is displayed in the output.\n",
    "\n",
    "Execute the following cell to initiate a prediction request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# FastAPI server URL\n",
    "FASTAPI_URL = \"http://localhost:8000/predict\"\n",
    "\n",
    "# Define the input data\n",
    "# In order of the features: UDI, Air temperature (K), Process temperature (K), Rotational speed (rpm), Torque (Nm), Tool wear (min), Type encoded, Product ID encoded, Failure Type encoded\n",
    "# Ensure to adjust the data based on actual possible inputs and features expected by the model\n",
    "payload = {\n",
    "    \"features\": [\n",
    "        2,          # UDI\n",
    "        310.5,      # Air temperature in Kelvin\n",
    "        320.1,      # Process temperature in Kelvin\n",
    "        2000,       # Rotational speed in rpm\n",
    "        50.5,       # Torque in Nm\n",
    "        10,         # Tool wear in minutes\n",
    "        1,          # Type encoded (categorical, numeric encoding)\n",
    "        8005,       # Product ID encoded (categorical, numeric encoding)\n",
    "        0           # Failure Type encoded (target variable, if used for retraining or similar scenarios)\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Send request to FastAPI\n",
    "response = requests.post(FASTAPI_URL, json=payload)\n",
    "\n",
    "# Handle response\n",
    "if response.status_code == 200:\n",
    "    print(\"Prediction:\", response.json())  # Print the predicted output, likely a machine failure prediction or similar\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)  # Handle errors like 404 or 500 from server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Information Retrieval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# # FastAPI server URL for the /model endpoint\n",
    "# FASTAPI_URL = \"http://localhost:8000/model\"\n",
    "\n",
    "# # Send request to FastAPI\n",
    "# response = requests.get(FASTAPI_URL)\n",
    "\n",
    "# # Handle response\n",
    "# if response.status_code == 200:\n",
    "#     model_info = response.json()\n",
    "#     print(\"Model Information:\")\n",
    "#     print(\"Hyperparameters:\", model_info[\"hyperparameters\"])\n",
    "#     print(\"Important Features:\", model_info[\"important_features\"])\n",
    "#     print(\"Input Schema:\", model_info[\"input_schema\"])\n",
    "# else:\n",
    "#     print(\"Error:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Drift Detection Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evidently AI Access from MLflow\n",
    "\n",
    "Insert instructions and demonstration on how to access the Evidently AI drift reports from MLflow\n",
    "\n",
    "Show Python code to access MLflow and retrieve the reports\n",
    "\n",
    "Show screenshots or directly embed the HTML reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drift Result Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Reproducability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
