{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. System Overview\n",
    "\n",
    "This machine learning system is designed to showcase an end-to-end implementation covering the entire lifecycle of a machine learning model. It integrates various MLOps tools and technologies discussed during the DASCI 270 sessions, that includes facilitating data ingestion, preprocessing, training, validation, deployment, and monitoring of the model. The system is also structured to handle drift detection to ensure the model remains effective and accurate over time. This document will guide you through interacting with the deployed system and provide detailed documentation of each component and their functionalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### System Architecture\n",
    "\n",
    "! insert diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Components\n",
    "\n",
    "1. **Machine Learning Model (XGBoost for Classification)** - \n",
    "\n",
    "2. **Data Pipeline (Dagster)** - Orchestrates the workflow for data ingestion, preprocessing, and preparation. Dagster manages the sequence of these operations to ensure data flows correctly from one process to another, maintaining a clear and manageable execution order.\n",
    "\n",
    "3. **Experiment Tracking (MLflow)** - Provides a framework to track experiments, including model training runs, parameters, metrics, and artifacts, enabling easier debugging and optimization. It stores models, performance metrics, and custom objects like drift reports, making them easy to access and compare across different runs.\n",
    "\n",
    "4. **Model Serving (FastAPI)** - Deploys the trained model through a REST API using FastAPI, facilitating easy access to the modelâ€™s predictive capabilities. The API handles requests for predictions and provides model metadata, ensuring input validation and structured outputs.\n",
    "\n",
    "5. **Containerization (Docker)** - Containerizes the services making up the system to ensure consistency and reproducibility across environments. Each isolated environment (\"container\") contains all necessary dependencies for each service, which can be easily deployed on any system supporting Docker.\n",
    "\n",
    "6. **Drift Detection (Evidently AI)** - Integrates Evidently AI to monitor the model for any signs of data or concept drift. This component is crucial for maintaining the model's accuracy, providing insights into how the data characteristics and relationships are changing over time.\n",
    "\n",
    "7. **Data Validation (Pydantic)** - Ensures that the data received by the API matches the expected format and type. This prevents errors during model prediction and ensures reliable model performance.\n",
    "\n",
    "8. **Testing (Pytest and Github Actions)** - Uses Pytest to develop and run comprehensive tests that validate the correctness of the data processing and feature engineering components. GitHub Actions automates these tests, ensuring that all code integrations meet quality standards and function as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Setup Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section provides detailed instructions on how to set up and run the system using Docker Compose. The instructions assume you have Docker and Docker Compose installed on your machine. If not, please install them from the [Docker official website](https://www.docker.com/) before proceeding.\n",
    "\n",
    "**Step 1: Clone the Repository**\n",
    "First, clone the project repository from GitHub to get the necessary code and configuration files. Use the following command:\n",
    "\n",
    "```python\n",
    "git clone https://github.com/raymundojavajr/ml-fp.git\n",
    "cd ml-fp\n",
    "```\n",
    "\n",
    "This command clones the repository into a directory named ml-fp on your local machine and changes into that directory.\n",
    "\n",
    "**Step 2: Configure Environment Variables**\n",
    "Create a .venv file in the root directory of the project to store environment variables. This can be conveniently done using uv:\n",
    "\n",
    "```python\n",
    "uv sync\n",
    "```\n",
    "\n",
    "It can also be done using pip:\n",
    "\n",
    "```python\n",
    "python -m .venv venv\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "**Step 3: Build the Docker Containers**\n",
    "Use Docker Compose to build the services defined in the docker-compose.yml file. This includes your Dagster orchestration, MLflow tracking server, and FastAPI application. Run the following command:\n",
    "\n",
    "```python\n",
    "docker-compose build\n",
    "```\n",
    "\n",
    "This command builds the Docker images for each service according to the specifications in the Dockerfile and docker-compose.yml files. It installs all necessary dependencies in these images, ensuring each service has what it needs to run.\n",
    "\n",
    "**Step 4: Run the Services**\n",
    "Once the images are built, you can start the services with the following command:\n",
    "\n",
    "```python\n",
    "docker-compose up\n",
    "```\n",
    "\n",
    "This command starts all services defined in docker-compose.yml. It creates and starts Docker containers for each service. The services will be networked together as defined, allowing them to communicate with each other.\n",
    "\n",
    "**Step 5: Access the Services**\n",
    "* FastAPI Application: Access the FastAPI application at http://localhost:8000. You will find the automatically generated API documentation there, which allows you to interact with the API directly through your web browser.\n",
    "* MLflow Tracking Server: Access the MLflow tracking server at http://localhost:5000. Here you can view and compare different model runs and their metrics.\n",
    "* Dagster Dagit UI: Access the Dagster orchestration UI at http://localhost:3000. This interface allows you to monitor and control the data pipelines.\n",
    "\n",
    "**Step 6: Shut Down the Services**\n",
    "To stop and remove all running containers, use the following command:\n",
    "\n",
    "```python\n",
    "docker-compose down\n",
    "```\n",
    "This command stops all containers and removes the containers, networks, and volumes created by docker-compose up. It cleans up everything except the built images, allowing for a quick restart of the services if needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Happy Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Information Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Drift Detection Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evidently AI Access from MLflow\n",
    "\n",
    "Insert instructions and demonstration on how to access the Evidently AI drift reports from MLflow\n",
    "\n",
    "Show Python code to access MLflow and retrieve the reports\n",
    "\n",
    "Show screenshots or directly embed the HTML reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drift Result Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data source https://archive.ics.uci.edu/dataset/601/ai4i+2020+predictive+maintenance+dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/raw/predictive_maintenance.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "UDI",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Product ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Air temperature [K]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Process temperature [K]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Rotational speed [rpm]",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Torque [Nm]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Tool wear [min]",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Target",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Failure Type",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b6aa0813-56d4-4a58-b33b-51f25ae647e2",
       "rows": [
        [
         "0",
         "1",
         "M14860",
         "M",
         "298.1",
         "308.6",
         "1551",
         "42.8",
         "0",
         "0",
         "No Failure"
        ],
        [
         "1",
         "2",
         "L47181",
         "L",
         "298.2",
         "308.7",
         "1408",
         "46.3",
         "3",
         "0",
         "No Failure"
        ],
        [
         "2",
         "3",
         "L47182",
         "L",
         "298.1",
         "308.5",
         "1498",
         "49.4",
         "5",
         "0",
         "No Failure"
        ],
        [
         "3",
         "4",
         "L47183",
         "L",
         "298.2",
         "308.6",
         "1433",
         "39.5",
         "7",
         "0",
         "No Failure"
        ],
        [
         "4",
         "5",
         "L47184",
         "L",
         "298.2",
         "308.7",
         "1408",
         "40.0",
         "9",
         "0",
         "No Failure"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UDI</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Target</th>\n",
       "      <th>Failure Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M14860</td>\n",
       "      <td>M</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L47181</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>No Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>L47182</td>\n",
       "      <td>L</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>No Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>L47183</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>No Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>L47184</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>No Failure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
       "0    1     M14860    M                298.1                    308.6   \n",
       "1    2     L47181    L                298.2                    308.7   \n",
       "2    3     L47182    L                298.1                    308.5   \n",
       "3    4     L47183    L                298.2                    308.6   \n",
       "4    5     L47184    L                298.2                    308.7   \n",
       "\n",
       "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Target Failure Type  \n",
       "0                    1551         42.8                0       0   No Failure  \n",
       "1                    1408         46.3                3       0   No Failure  \n",
       "2                    1498         49.4                5       0   No Failure  \n",
       "3                    1433         39.5                7       0   No Failure  \n",
       "4                    1408         40.0                9       0   No Failure  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "df = df.copy()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Define Data Columns\n",
    "categorical_cols = [\"Type\", \"Product ID\", \"Failure Type\"]\n",
    "numerical_cols = [\n",
    "    \"Air temperature [K]\",\n",
    "    \"Process temperature [K]\",\n",
    "    \"Rotational speed [rpm]\",\n",
    "    \"Torque [Nm]\",\n",
    "    \"Tool wear [min]\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_data_columns():\n",
    "    categorical_cols = [\"Type\", \"Product ID\", \"Failure Type\"]\n",
    "\n",
    "    numerical_cols = [\n",
    "    \"Air temperature [K]\",\n",
    "    \"Process temperature [K]\",\n",
    "    \"Rotational speed [rpm]\",\n",
    "    \"Torque [Nm]\",\n",
    "    \"Tool wear [min]\",\n",
    "]\n",
    "    return categorical_cols, numerical_cols\n",
    "\n",
    "cat_cols, num_cols = define_data_columns()\n",
    "print(\"Categorical Columns:\", cat_cols)\n",
    "print(\"Numerical Columns:\", num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label enconding\n",
    "le_dict = {}\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col + \"_encoded\"] = le.fit_transform(df[col])\n",
    "    le_dict[col] = le\n",
    "\n",
    "print(\"encoded columns:\")\n",
    "print (df[[col + \"_encoded\" for col in cat_cols]].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = numerical_cols + [col + \"_encoded\" for col in categorical_cols]\n",
    "features_array = df[feature_cols].values\n",
    "features_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_binary = df[\"Target\"].values\n",
    "y_multiclass = df[\"Failure Type_encoded\"].values\n",
    "\n",
    "mi_scores = mutual_info_classif(features_array, y_binary)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"mi_scores\": mi_scores\n",
    "})\n",
    "\n",
    "feature_importance = feature_importance.sort_values(by=\"mi_scores\", ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the mutual information scores as a bar chart\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(feature_importance[\"feature\"], feature_importance[\"mi_scores\"], color=\"skyblue\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Mutual Information Score\")\n",
    "plt.title(\"Feature Importance Based on Mutual Information\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = mi_scores.mean()\n",
    "\n",
    "selected_features = feature_importance[feature_importance[\"mi_scores\"] > threshold][\"feature\"].tolist()\n",
    "X = df[selected_features].values\n",
    "\n",
    "\n",
    "# Display the selected features and the shape of the resulting feature matrix.\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross validation\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "binary_predictions = np.zeros(len(df))\n",
    "multiclass_predictions = np.zeros(len(df))\n",
    "\n",
    "f1_scores = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y_binary[train_idx], y_binary[val_idx]\n",
    "    y_train_multi, y_val_multi = y_multiclass[train_idx], y_multiclass[val_idx]\n",
    "\n",
    "    # --- Binary Classification Model ---\n",
    "    binary_model = XGBClassifier(random_state=42, eval_metric=\"logloss\")\n",
    "    binary_model.fit(X_train, y_train)\n",
    "    binary_pred = binary_model.predict(X_val)\n",
    "    fold_f1 = f1_score(y_val, binary_pred)\n",
    "    f1_scores.append(fold_f1)\n",
    "    print(f\"Fold {fold + 1} - Binary F1 Score: {fold_f1:.4f}\")\n",
    "    binary_predictions[val_idx] = binary_pred\n",
    "\n",
    "    # --- Multiclass Classification Model ---\n",
    "    multiclass_model = XGBClassifier(random_state=42, eval_metric=\"mlogloss\")\n",
    "    multiclass_model.fit(X_train, y_train_multi)\n",
    "    multiclass_predictions[val_idx] = multiclass_model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Step 8: Create Submission DataFrame\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# Create the submission DataFrame using:\n",
    "# - \"UDI\": Unique identifiers from the original dataset.\n",
    "# - \"Target\": Binary predictions (converted to integers).\n",
    "# - \"Failure_Type\": Multiclass predictions are inverse-transformed back to original labels.\n",
    "submission = pd.DataFrame({\n",
    "    \"UDI\": df[\"UDI\"],\n",
    "    \"Target\": binary_predictions.astype(int),\n",
    "    \"Failure_Type\": le_dict[\"Failure Type\"].inverse_transform(multiclass_predictions.astype(int))\n",
    "})\n",
    "\n",
    "# Display the first few rows of the submission DataFrame\n",
    "print(\"Submission preview:\")\n",
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
